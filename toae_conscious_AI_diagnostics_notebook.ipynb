{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ToAE Diagnostics Prototype (Toy GRU Agent)\n",
        "\n",
        "This notebook implements a minimal prototype of the ToAE diagnostics described in Section 4\u20135.\n",
        "It is intentionally self-contained and runs on CPU. It demonstrates:\n",
        "\n",
        "- a small GRU-based model used as a toy folding system;\n",
        "- `fold_fn`, `converge`, and `perturb` primitives;\n",
        "- PSC (Predictive Self-Consistency) probe training and evaluation;\n",
        "- Folding depth (D) estimation;\n",
        "- Attractor Stability (AS) estimation via Gaussian perturbations.\n",
        "\n",
        "Run the notebook from top to bottom. Outputs and example metrics will be saved to `/mnt/data`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: imports and simple utilities\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os, json, math, random\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a small GRU-based folding model\n",
        "class ToyGRUAgent(nn.Module):\n",
        "    def __init__(self, input_dim=8, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.gru_cell = nn.GRUCell(hidden_dim, hidden_dim)\n",
        "        self.readout = nn.Linear(hidden_dim, input_dim)  # optional decoder\n",
        "    def initial_state(self, batch_size=1):\n",
        "        return torch.zeros(batch_size, self.gru_cell.hidden_size, device=device)\n",
        "    def encode_input(self, x):\n",
        "        # x: (batch, input_dim)\n",
        "        return self.encoder(x)\n",
        "    def fold_step(self, s, x):\n",
        "        # s: (batch, hidden), x: (batch, input_dim)\n",
        "        ex = self.encode_input(x)\n",
        "        s_next = self.gru_cell(ex, s)\n",
        "        return s_next\n",
        "    def forward(self, s, x, steps=1):\n",
        "        # apply fold steps\n",
        "        for _ in range(steps):\n",
        "            s = self.fold_step(s, x)\n",
        "        return s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Synthetic dataset generator: simple sequences where next input depends on previous token\n",
        "def generate_synthetic_sequences(N=1000, seq_len=10, input_dim=8):\n",
        "    data = []\n",
        "    for _ in range(N):\n",
        "        seq = np.random.randn(seq_len, input_dim).astype(np.float32)\n",
        "        # add a small deterministic trend so states have some structure\n",
        "        seq = seq + np.linspace(0,1,seq_len)[:,None]*0.05\n",
        "        data.append(seq)\n",
        "    return data\n",
        "\n",
        "# create data\n",
        "data = generate_synthetic_sequences(N=1200, seq_len=12, input_dim=8)\n",
        "print('Generated', len(data), 'sequences of length', len(data[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utilities: state extractor and collecting (s_t, s_{t+1}) pairs\n",
        "def extract_state(model, seq, t, pool='last'):\n",
        "    # seq: numpy array (seq_len, input_dim)\n",
        "    x = torch.tensor(seq[t], device=device).unsqueeze(0)\n",
        "    s0 = model.initial_state(batch_size=1)\n",
        "    # run fold for single step starting from zero-state to get state at t (simple proxy)\n",
        "    s = model.fold_step(s0, x)\n",
        "    return s.detach().cpu().numpy().squeeze()\n",
        "\n",
        "def collect_state_pairs(model, sequences, max_pairs=2000):\n",
        "    pairs = []\n",
        "    for seq in sequences:\n",
        "        L = len(seq)\n",
        "        for t in range(L-1):\n",
        "            s = extract_state(model, seq, t)\n",
        "            s_next = extract_state(model, seq, t+1)\n",
        "            pairs.append((s, s_next))\n",
        "            if len(pairs) >= max_pairs:\n",
        "                return pairs\n",
        "    return pairs\n",
        "\n",
        "# initialize model and collect pairs\n",
        "model = ToyGRUAgent(input_dim=8, hidden_dim=64).to(device)\n",
        "pairs = collect_state_pairs(model, data, max_pairs=1500)\n",
        "print('Collected', len(pairs), 'state pairs')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a small probe (MLP) to predict s_{t+1} from s_t\n",
        "class Probe(nn.Module):\n",
        "    def __init__(self, dim=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def train_probe(pairs, epochs=30, batch_size=64, lr=1e-3):\n",
        "    X = np.stack([p[0] for p in pairs])\n",
        "    Y = np.stack([p[1] for p in pairs])\n",
        "    perm = np.random.permutation(len(X))\n",
        "    split = int(0.8*len(X))\n",
        "    train_idx = perm[:split]\n",
        "    val_idx = perm[split:]\n",
        "    X_train, Y_train = torch.tensor(X[train_idx], device=device), torch.tensor(Y[train_idx], device=device)\n",
        "    X_val, Y_val = torch.tensor(X[val_idx], device=device), torch.tensor(Y[val_idx], device=device)\n",
        "    probe = Probe(dim=X.shape[1]).to(device)\n",
        "    opt = optim.Adam(probe.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    for ep in range(epochs):\n",
        "        probe.train()\n",
        "        perm = torch.randperm(X_train.size(0))\n",
        "        losses = []\n",
        "        for i in range(0, X_train.size(0), batch_size):\n",
        "            idx = perm[i:i+batch_size]\n",
        "            xb, yb = X_train[idx], Y_train[idx]\n",
        "            pred = probe(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "            losses.append(loss.item())\n",
        "        if (ep+1) % 10 == 0:\n",
        "            probe.eval()\n",
        "            with torch.no_grad():\n",
        "                val_loss = loss_fn(probe(X_val), Y_val).item()\n",
        "            print(f'Probe epoch {ep+1} train_loss {np.mean(losses):.5f} val_loss {val_loss:.5f}')\n",
        "    return probe, (X_val, Y_val)\n",
        "\n",
        "probe, val_data = train_probe(pairs, epochs=40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute PSC: 1 - mse / var\n",
        "def compute_PSC(probe, val_tuple):\n",
        "    X_val, Y_val = val_tuple\n",
        "    probe.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = probe(X_val)\n",
        "        mse = torch.mean((pred - Y_val)**2).item()\n",
        "        var = torch.mean(Y_val**2).item() - torch.mean(Y_val).pow(2).item()\n",
        "        PSC = 1.0 - mse / (var + 1e-9)\n",
        "    return PSC, mse, var\n",
        "\n",
        "PSC, mse, var = compute_PSC(probe, val_data)\n",
        "print('PSC:', PSC, 'mse', mse, 'var', var)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define fold_fn and converge for this GRU model (using same input x repeatedly as a simple demo)\n",
        "def fold_fn(model, s, x):\n",
        "    # x: numpy or torch single-step input vector (1, input_dim)\n",
        "    if not isinstance(x, torch.Tensor):\n",
        "        x = torch.tensor(x, device=device).unsqueeze(0)\n",
        "    if not isinstance(s, torch.Tensor):\n",
        "        s = torch.tensor(s, device=device)\n",
        "    with torch.no_grad():\n",
        "        s_next = model.fold_step(s, x)\n",
        "    return s_next\n",
        "\n",
        "def converge(model, s0, x, fold_fn, max_iters=50, eps=1e-4, momentum=0.0):\n",
        "    s = s0.clone().detach()\n",
        "    for k in range(max_iters):\n",
        "        s_next = fold_fn(model, s, x)\n",
        "        if momentum > 0:\n",
        "            s_next = momentum * s + (1.0 - momentum) * s_next\n",
        "        if torch.norm(s_next - s).item() < eps:\n",
        "            return s_next, k+1\n",
        "        s = s_next\n",
        "    return s, max_iters\n",
        "\n",
        "# Quick test: converge starting from zero state with a fixed input\n",
        "x0 = torch.tensor(data[0][0], device=device).unsqueeze(0)\n",
        "s0 = model.initial_state(batch_size=1)\n",
        "s_conv, steps = converge(model, s0, x0, fold_fn)\n",
        "print('Converged in steps', steps, 'state norm', torch.norm(s_conv).item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute folding depth D for a set of inputs\n",
        "def compute_D_for_inputs(model, sequences, fold_fn, Kmax=50, eps=1e-4):\n",
        "    Ds = []\n",
        "    for seq in sequences[:200]:\n",
        "        x0 = torch.tensor(seq[0], device=device).unsqueeze(0)\n",
        "        s0 = model.initial_state(batch_size=1)\n",
        "        s_conv, steps = converge(model, s0, x0, fold_fn, max_iters=Kmax, eps=eps)\n",
        "        Ds.append(steps)\n",
        "    return Ds\n",
        "\n",
        "Ds = compute_D_for_inputs(model, data, fold_fn, Kmax=50, eps=1e-5)\n",
        "import statistics\n",
        "print('D mean', statistics.mean(Ds), 'median', statistics.median(Ds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute Attractor Stability (AS) via Gaussian perturbations around attractor\n",
        "def perturb_gaussian(s, sigma=0.01):\n",
        "    # s: torch tensor (1, hidden)\n",
        "    noise = torch.randn_like(s) * sigma * torch.norm(s)\n",
        "    return s + noise\n",
        "\n",
        "def compute_AS_for_input(model, seq, fold_fn, N=100, sigma=0.02):\n",
        "    x0 = torch.tensor(seq[0], device=device).unsqueeze(0)\n",
        "    s0 = model.initial_state(batch_size=1)\n",
        "    a, _ = converge(model, s0, x0, fold_fn)\n",
        "    diffs = []\n",
        "    for i in range(N):\n",
        "        s_pert = perturb_gaussian(a, sigma=sigma)\n",
        "        a_i, _ = converge(model, s_pert, x0, fold_fn)\n",
        "        diffs.append(torch.norm(a_i - a).item() / (torch.norm(a).item() + 1e-9))\n",
        "    AS = 1.0 - float(np.mean(diffs))\n",
        "    return AS, diffs\n",
        "\n",
        "AS_example, diffs = compute_AS_for_input(model, data[0], fold_fn, N=80, sigma=0.02)\n",
        "print('AS example', AS_example)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save example metrics and small report\n",
        "out = {\n",
        "    'PSC': float(PSC),\n",
        "    'D_mean': float(sum(Ds)/len(Ds)),\n",
        "    'D_median': float(sorted(Ds)[len(Ds)//2]),\n",
        "    'AS_example': float(AS_example)\n",
        "}\n",
        "os.makedirs('/mnt/data/toae_notebook_outputs', exist_ok=True)\n",
        "with open('/mnt/data/toae_notebook_outputs/report.json', 'w') as f:\n",
        "    json.dump(out, f, indent=2)\n",
        "print('Saved report to /mnt/data/toae_notebook_outputs/report.json')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}